<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Nonmanual | Vadim Kimmelman</title>
<meta name="generator" content="Jekyll v3.8.4" />
<meta property="og:title" content="Nonmanual" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Sign language linguist" />
<meta property="og:description" content="Sign language linguist" />
<link rel="canonical" href="http://localhost:4000/nonmanual/" />
<meta property="og:url" content="http://localhost:4000/nonmanual/" />
<meta property="og:site_name" content="Vadim Kimmelman" />
<script type="application/ld+json">
{"url":"http://localhost:4000/nonmanual/","description":"Sign language linguist","@type":"WebPage","headline":"Nonmanual","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Vadim Kimmelman" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Vadim Kimmelman</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/research/">Research</a><a class="page-link" href="/nonmanual/">Nonmanual</a><a class="page-link" href="/publications/">Publications</a><a class="page-link" href="/presentations/">Presentations</a><a class="page-link" href="/russian/">Русская версия</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <h1 class="post-title">Nonmanual</h1>
  </header>

  <div class="post-content">
    <h1 id="fundamentals-of-formal-properties-of-nonmanuals--a-quantitative-approach"><strong>Fundamentals of formal properties of nonmanuals: <br /> A quantitative approach</strong></h1>

<p><img src="/img/nonmanuals.png" alt="" />
<br /></p>

<h1 id="about-the-project">About the project</h1>

<p>The project “Fundamentals of formal properties of nonmanuals: A quantitative approach” (NONMANUAL) is funded by the European Research Council (<a href="https://erc.easme-web.eu/?p=101039378">link to the project in the ERC Datahub</a>). It will run from January 2023 to December 2027.</p>

<p>If you are interested in collaborating on topics related to this project,  do not hesitate to email me.</p>

<p><br /></p>

<h1 id="summary">Summary</h1>

<p>Sign languages, in addition to using the hands, also use positions and movements of other articulators: the body, the head, the mouth, the eyebrows, the eyes and the eyelids, to convey lexical, grammatical, and prosodic information. This linguistic use of the nonmanual articulators is known as nonmanuals. Contrary to current assumptions in the field of sign linguistics, this project proposes the hypothesis that all sign languages use the same basic universal building blocks (nonmanual movements) but that each language is different in how it combines these building blocks both sequentially and simultaneously; languages also differ in the regularity, frequency, and the alignment properties of the nonmanuals.</p>

<p>In order to test this hypothesis, the project will investigate formal properties of nonmanuals in five geographically, historically, and socially diverse sign languages using data from published naturalistic corpora of the sign languages, Computer Vision for extracting measurements of the movement of nonmanual articulators, and a statistical techniques of Non-linear Mixed Effect Modelling and Functional Data Analysis for a quantitative comparison of dynamic nonmanual contours. This will result in the first quantitative formal typology of nonmanuals grounded in naturalistic corpus data. The novel methodology proposed in this project requires testing, adjustment, and development, which constitutes an important component of the project. The developed methodological pipeline will be a secondary output enabling large-scale reliable quantitative research on nonmanuals in future.</p>

<p>Finally, the established typology of formal properties of nonmanuals in the five sign languages will serve as basis for a cross-modal comparison between nonmanuals and prosody/intonation in spoken languages in order to separate truly universal features of the human linguistic capacity from the effects of the visual vs. auditory modalities.</p>

<p><br /></p>

<h1 id="the-team">The team</h1>

<ul>
  <li>
    <p>PI: <a href="vadimkimmelman.com">Vadim Kimmelman</a></p>
  </li>
  <li>
    <p>Postdoctoral researcher: the position will be advertised shortly</p>
  </li>
  <li>
    <p>PhD student: the position will be advertised shortly</p>
  </li>
  <li>
    <p>PhD student: the position will be advertised shortly</p>
  </li>
  <li>
    <p>Statistician: <a href="https://www.uib.no/personer/Jan.Bulla">Jan Bulla</a></p>
  </li>
</ul>

<p><strong>Collaborations with</strong> <a href="https://github.com/kuzanna2016">Anna Kuznetsova</a>, <a href="https://orcid.org/0000-0002-5091-7664">Anastasiia Chizhikova</a>, <a href="https://research.nu.edu.kz/en/persons/anara-sandygulova">Anara Sandygulova</a>, <a href="https://scholar.google.de/citations?user=HPTthwYAAAAJ&amp;hl=en">Medet Mukushev</a>, Alfarabi Imashev</p>

<p><br /></p>

<h1 id="output">Output</h1>

<p>The project officially kicks off in 2023. However, I have co-authored several studies that were pilots for the research that will be conducted within this project:</p>

<p>Kimmelman, V., A. Imashev, M. Mukushev &amp; A. Sandygulova. (2020). Eyebrow position in grammatical and emotional expressions in Kazakh-Russian Sign Language: A quantitative study. <em>PLOS ONE</em> 15(6). <a href="https://doi.org/10.1371/journal.pone.0233731">https://doi.org/10.1371/journal.pone.0233731</a> (open access)</p>
<ul>
  <li><em>In this study, we applied a Computer Vision tool (OpenPose) to quantitatively analyze eyebrow position as affected by three sentence types and three different emotions in utterances produced by ten signers. See a video below demonstrating application of the tool and sentence types.</em></li>
</ul>

<iframe width="560" height="315" src="https://www.youtube.com/embed/_avV5W8k7ZI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<p><br /></p>

<p>Kuznetsova, A., A. Imashev, M. Mukushev, A. Sandygulova &amp; V. Kimmelman (2021). Using Computer
Vision to Analyze Non-manual Marking of Questions in KRSL. In D. Shterionov (ed.) <em>Proceedings
of the 1st International Workshop on Automatic Translation for Signed and Spoken Languages
(AT4SSL)</em>, (pp. 49-59). Association for Machine Translation in the Americas. <a href="https://aclanthology.org/2021.mtsummit-at4ssl.6/">https://aclanthology.org/2021.mtsummit-at4ssl.6/</a> (open access)</p>
<ul>
  <li><em>In this study, we re-analyzed parts of the data from the previous study using a different CV-tool (OpenFace) and applying Machine Learning to improve the measurements of eyebrow movements.</em></li>
</ul>

<p>Kuznetsova, A., Imashev, A., Mukushev, M., Sandygulova, A., &amp; Kimmelman, V. (2022). Functional Data Analysis of Non-manual Marking of Questions in Kazakh-Russian Sign Language. In E. Efthimiou, S.-E. Fotinea, T. Hanke, J. A. Hochgesang, J. Kristoffersen, J. Mesch, &amp; M. Schulder (Eds.), <em>Proceedings of the LREC2022 10th Workshop on the Representation and Processing of Sign Languages: Multilingual Sign Language Resources</em> (pp. 124-131). European Language Resources Association (ELRA). <a href="https://www.sign-lang.uni-hamburg.de/lrec/pub/22024.pdf">https://www.sign-lang.uni-hamburg.de/lrec/pub/22024.pdf</a></p>
<ul>
  <li><em>In this study, we improved the statistical analysis of the data from the previous study in order to account for the dynamic nature of eyebrow and head movements. The figure below shows application of FDA analysis to head movement and inner and outer eyebrow movement across different sentence types with and without landmark registration (time alignment to sign boundaries).</em></li>
</ul>

<p><img src="/img/fda.png" alt="" /></p>

<p>Chizhikova, A., &amp; Kimmelman, V. (2022). Phonetics of Negative Headshake in Russian Sign Language: A Small-Scale Corpus Study. In E. Efthimiou, S.-E. Fotinea, T. Hanke, J. A. Hochgesang, J. Kristoffersen, J. Mesch, &amp; M. Schulder (Eds.), <em>Proceedings of the LREC2022 10th Workshop on the Representation and Processing of Sign Languages: Multilingual Sign Language Resources</em> (pp. 29-36). European Language Resources Association (ELRA). <a href="https://www. sign-lang.uni-hamburg.de/lrec/pub/22011.pdf">https://www. sign-lang.uni-hamburg.de/lrec/pub/22011.pdf</a></p>
<ul>
  <li><em>In this study, we analyzed phonetic properties of headshake expressing negation in Russian Sign Language using OpenFace. Example of a headshake measured as head rotation in OpenFace:</em></li>
</ul>

<p><img src="/img/headshake1.png" alt="" /></p>

<p><br /></p>


  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Vadim Kimmelman</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Vadim Kimmelman</li><li><a class="u-email" href="mailto:vadim.kimmelman@gmail.com">vadim.kimmelman@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Sign language linguist</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
